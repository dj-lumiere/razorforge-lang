# RazorForge uaddr (system-sized unsigned integer) native type implementation
# Maps to LLVM pointer-sized integer - u32 on 32-bit, u64 on 64-bit platforms
# Used for array indices, sizes, and pointer arithmetic
#
# SAFETY: uaddr does NOT support base arithmetic operators (+, -, *, //, %, **, <<)
# to prevent silent overflow bugs in pointer/size calculations.
# You must use explicit wrapping (+%, -%, etc.) or checked (+?, -?, etc.) variants.

namespace core

import Text/Text
import FFI/cstr

# Core uaddr type definition - maps to LLVM iptr/usize
record uaddr {
    public value: @intrinsic.iptr
}

# ============================================================================
# Constructors
# Since they are black hole types, all constructors are automatically wrapped.
# ============================================================================

routine uaddr.__create__!(from_text: Text<Letter>) -> uaddr {
    danger! {
        return @native.rf_parse_uaddr(from_text)
    }
}

# From s8 - sign extend then reinterpret (wraps if negative)
routine uaddr.__create__(from: s8) -> uaddr {
    danger! {
        return @intrinsic.sext<i8, uptr>(from)
    }
}

# From s16 - sign extend then reinterpret (wraps if negative)
routine uaddr.__create__(from: s16) -> uaddr {
    danger! {
        return @intrinsic.sext<i16, uptr>(from)
    }
}

# From s32 - sign extend then reinterpret (wraps if negative)
routine uaddr.__create__(from: s32) -> uaddr {
    danger! {
        return @intrinsic.sext<i32, uptr>(from)
    }
}

# From s64 - truncate or bitcast depending on platform (wraps)
routine uaddr.__create__(from: s64) -> uaddr {
    danger! {
        return @intrinsic.trunc<i64, uptr>(from)
    }
}

# From s128 - truncate (wraps)
routine uaddr.__create__(from: s128) -> uaddr {
    danger! {
        return @intrinsic.trunc<i128, uptr>(from)
    }
}

# From u8 - zero extend
routine uaddr.__create__(from: u8) -> uaddr {
    danger! {
        return @intrinsic.zext<i8, uptr>(from)
    }
}

# From u16 - zero extend
routine uaddr.__create__(from: u16) -> uaddr {
    danger! {
        return @intrinsic.zext<i16, uptr>(from)
    }
}

# From u32 - zero extend or bitcast depending on platform
routine uaddr.__create__(from: u32) -> uaddr {
    danger! {
        return @intrinsic.zext<i32, uptr>(from)
    }
}

# From u64 - truncate or bitcast depending on platform (wraps)
routine uaddr.__create__(from: u64) -> uaddr {
    danger! {
        return @intrinsic.trunc<i64, uptr>(from)
    }
}

# From u128 - truncate (wraps)
routine uaddr.__create__(from: u128) -> uaddr {
    danger! {
        return @intrinsic.trunc<i128, uptr>(from)
    }
}

# From floating point - truncates
routine uaddr.__create__(from: f16) -> uaddr {
    return from.f32().uaddr()
}

routine uaddr.__create__(from: f32) -> uaddr {
    danger! {
        return @intrinsic.fptoui<float, uptr>(from)
    }
}

routine uaddr.__create__(from: f64) -> uaddr {
    danger! {
        return @intrinsic.fptoui<double, uptr>(from)
    }
}

routine uaddr.__create__(from: f128) -> uaddr {
    return from.f64().uaddr()
}

# From decimal - truncates fractional part (wraps on overflow)
routine uaddr.__create__(from: d32) -> uaddr {
    danger! {
        let bit_width = @intrinsic.bitwidth<uptr>()
        if bit_width == 32 {
            return from.u32().uaddr()
        } else {
            return from.u64().uaddr()
        }
    }
}

routine uaddr.__create__(from: d64) -> uaddr {
    danger! {
        let bit_width = @intrinsic.bitwidth<uptr>()
        if bit_width == 32 {
            return from.u32().uaddr()
        } else {
            return from.u64().uaddr()
        }
    }
}

routine uaddr.__create__(from: d128) -> uaddr {
    danger! {
        let bit_width = @intrinsic.bitwidth<uptr>()
        if bit_width == 32 {
            return from.u32().uaddr()
        } else {
            return from.u64().uaddr()
        }
    }
}

routine uaddr.__create__(from: saddr) -> uaddr {
    return from.u64().saddr()
}

# Identity conversion for Integral protocol compatibility
routine uaddr.__create__(from: uaddr) -> uaddr {
    return from
}

# ============================================================================
# Wrapping Arithmetic Operations (+%, -%, *%, //%, %%, **%)
# These explicitly wrap on overflow - use when wrapping is intentional
# ============================================================================

routine uaddr.__add_wrap__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.add.wrapping<uptr>(me, you)
    }
}

routine uaddr.__sub_wrap__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.sub.wrapping<uptr>(me, you)
    }
}

routine uaddr.__mul_wrap__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.mul.wrapping<uptr>(me, you)
    }
}

routine uaddr.__floordiv_wrap__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.udiv<uptr>(me, you)
    }
}

routine uaddr.__mod_wrap__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.urem<uptr>(me, you)
    }
}

# ============================================================================
# Checked Arithmetic Operations (+?, -?, *?, //?, %?, **?, <<?)
# These return Maybe<uaddr> - None on overflow
# ============================================================================

routine uaddr.__add_checked__(you: uaddr) -> Maybe<uaddr> {
    danger! {
        let (result, overflow) = @intrinsic.add.overflow<uptr>(me, you)
        return if overflow then None else result
    }
}

routine uaddr.__sub_checked__(you: uaddr) -> Maybe<uaddr> {
    danger! {
        let (result, overflow) = @intrinsic.sub.overflow<uptr>(me, you)
        return if overflow then None else result
    }
}

routine uaddr.__mul_checked__(you: uaddr) -> Maybe<uaddr> {
    danger! {
        let (result, overflow) = @intrinsic.mul.overflow<uptr>(me, you)
        return if overflow then None else result
    }
}

routine uaddr.__floordiv_checked__(you: uaddr) -> Maybe<uaddr> {
    if you == 0 {
        return None
    }
    danger! {
        return @intrinsic.udiv<uptr>(me, you)
    }
}

routine uaddr.__mod_checked__(you: uaddr) -> Maybe<uaddr> {
    if you == 0 {
        return None
    }
    danger! {
        return @intrinsic.urem<uptr>(me, you)
    }
}

routine uaddr.__ashl_checked__(bits: u32) -> Maybe<uaddr> {
    danger! {
        # Check if shift would overflow (bits >= bit width or high bits would be lost)
        let bit_width = @intrinsic.bitwidth<uptr>()
        if bits >= bit_width {
            return None
        }
        let result = @intrinsic.shl<uptr>(me, bits)
        # Check if we can recover the original value by shifting back
        let recovered = @intrinsic.lshr<uptr>(result, bits)
        if recovered != me {
            return None
        }
        return result
    }
}

# ============================================================================
# Shift Operations (<<<, >>>)
# uaddr does NOT have >> (sign-preserving right shift) - use >>> instead
# ============================================================================

routine uaddr.__lshl__(bits: u32) -> uaddr {
    danger! {
        return @intrinsic.shl<uptr>(me, bits)
    }
}

routine uaddr.__lshr__(bits: u32) -> uaddr {
    danger! {
        return @intrinsic.lshr<uptr>(me, bits)
    }
}

# ============================================================================
# Bitwise Operations (&, |, ^, ~)
# These cannot overflow
# ============================================================================

routine uaddr.__and__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.and<uptr>(me, you)
    }
}

routine uaddr.__or__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.or<uptr>(me, you)
    }
}

routine uaddr.__xor__(you: uaddr) -> uaddr {
    danger! {
        return @intrinsic.xor<uptr>(me, you)
    }
}

routine uaddr.__not__() -> uaddr {
    danger! {
        return @intrinsic.not<uptr>(me)
    }
}

# ============================================================================
# Comparison Operations (non-overloadable, but provided for completeness)
# ============================================================================

routine uaddr.__lt__(you: uaddr) -> bool {
    danger! {
        return @intrinsic.icmp.ult<uptr>(me, you)
    }
}

routine uaddr.__le__(you: uaddr) -> bool {
    danger! {
        return @intrinsic.icmp.ule<uptr>(me, you)
    }
}

routine uaddr.__gt__(you: uaddr) -> bool {
    danger! {
        return @intrinsic.icmp.ugt<uptr>(me, you)
    }
}

routine uaddr.__ge__(you: uaddr) -> bool {
    danger! {
        return @intrinsic.icmp.uge<uptr>(me, you)
    }
}

# ============================================================================
# Utility Methods
# ============================================================================

routine uaddr.min(you: uaddr) -> uaddr {
    if me <= you {
        return me
    }
    return you
}

routine uaddr.max(you: uaddr) -> uaddr {
    if me >= you {
        return me
    }
    return you
}

routine uaddr.is_power_of_two() -> bool {
    return me != 0 and (me & (me -% 1)) == 0
}

# ============================================================================
# String Conversion
# ============================================================================

routine uaddr.to_text() -> Bytes {
    danger! {
        let ptr = @native.rf_format_u64(me)
        return Bytes(ptr: cstr(ptr: ptr))
    }
}
