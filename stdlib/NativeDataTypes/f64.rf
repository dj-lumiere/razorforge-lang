# RazorForge f64 (double precision floating point) native type implementation
# Maps directly to LLVM double type and IEEE 754 double precision format

# Core f64 type definition - maps to LLVM double
record f64 {
    public value: LlvmNativeDouble
}

# IEEE 754 double precision constants
preset F64_EPSILON: f64 = 2.220446049250313e-16
preset F64_MIN: f64 = 2.2250738585072014e-308
preset F64_MAX: f64 = 1.7976931348623157e+308
preset F64_MIN_POSITIVE: f64 = 2.2250738585072014e-308
preset F64_INFINITY: f64 = 1.0 / 0.0
preset F64_NEG_INFINITY: f64 = -1.0 / 0.0
preset F64_NAN: f64 = 0.0 / 0.0

# Mathematical constants
preset F64_PI: f64 = 3.141592653589793
preset F64_E: f64 = 2.718281828459045
preset F64_SQRT_2: f64 = 1.4142135623730951
preset F64_LN_2: f64 = 0.6931471805599453
preset F64_LN_10: f64 = 2.302585092994046

# Basic arithmetic operations (LLVM floating point intrinsics)

# Addition - maps to LLVM fadd
routine f64.add(me: f64, other: f64) -> f64 {
    return llvm_intrinsic("fadd", me, other)
}

# Subtraction - maps to LLVM fsub
routine f64.sub(me: f64, other: f64) -> f64 {
    return llvm_intrinsic("fsub", me, other)
}

# Multiplication - maps to LLVM fmul
routine f64.mul(me: f64, other: f64) -> f64 {
    return llvm_intrinsic("fmul", me, other)
}

# Division - maps to LLVM fdiv
routine f64.div(me: f64, other: f64) -> f64 {
    return llvm_intrinsic("fdiv", me, other)
}

# Remainder - maps to LLVM frem
routine f64.rem(me: f64, other: f64) -> f64 {
    return llvm_intrinsic("frem", me, other)
}

# Comparison operations (LLVM fcmp)
routine f64.eq(me: f64, other: f64) -> bool {
    return llvm_intrinsic("fcmp oeq", me, other)  # Ordered equal
}

routine f64.ne(me: f64, other: f64) -> bool {
    return llvm_intrinsic("fcmp one", me, other)  # Ordered not equal
}

routine f64.lt(me: f64, other: f64) -> bool {
    return llvm_intrinsic("fcmp olt", me, other)  # Ordered less than
}

routine f64.le(me: f64, other: f64) -> bool {
    return llvm_intrinsic("fcmp ole", me, other)  # Ordered less equal
}

routine f64.gt(me: f64, other: f64) -> bool {
    return llvm_intrinsic("fcmp ogt", me, other)  # Ordered greater than
}

routine f64.ge(me: f64, other: f64) -> bool {
    return llvm_intrinsic("fcmp oge", me, other)  # Ordered greater equal
}

# NaN-aware comparisons
routine f64.is_nan(me: f64) -> bool {
    return llvm_intrinsic("fcmp uno", me, me)   # Unordered (NaN check)
}

routine f64.is_finite(me: f64) -> bool {
    not me.is_nan() and not me.is_infinite()
}

routine f64.is_infinite(me: f64) -> bool {
    me == F64_INFINITY or me == F64_NEG_INFINITY
}

# Mathematical functions using LLVM intrinsics
routine f64.abs(me: f64) -> f64 {
    return llvm_intrinsic("llvm.fabs.f64", me)
}

routine f64.sqrt(me: f64) -> f64 {
    return llvm_intrinsic("llvm.sqrt.f64", me)
}

routine f64.sin(me: f64) -> f64 {
    return llvm_intrinsic("llvm.sin.f64", me)
}

routine f64.cos(me: f64) -> f64 {
    return llvm_intrinsic("llvm.cos.f64", me)
}

routine f64.tan(me: f64) -> f64 {
    return me.sin() / me.cos()
}

routine f64.pow(me: f64, exponent: f64) -> f64 {
    return llvm_intrinsic("llvm.pow.f64", me, exponent)
}

routine f64.exp(me: f64) -> f64 {
    return llvm_intrinsic("llvm.exp.f64", me)
}

routine f64.exp2(me: f64) -> f64 {
    return llvm_intrinsic("llvm.exp2.f64", me)
}

routine f64.ln(me: f64) -> f64 {
    return llvm_intrinsic("llvm.log.f64", me)
}

routine f64.log2(me: f64) -> f64 {
    return llvm_intrinsic("llvm.log2.f64", me)
}

routine f64.log10(me: f64) -> f64 {
    return llvm_intrinsic("llvm.log10.f64", me)
}

# Rounding and truncation
routine f64.floor(me: f64) -> f64 {
    return llvm_intrinsic("llvm.floor.f64", me)
}

routine f64.ceil(me: f64) -> f64 {
    return llvm_intrinsic("llvm.ceil.f64", me)
}

routine f64.round(me: f64) -> f64 {
    return llvm_intrinsic("llvm.round.f64", me)
}

routine f64.trunc(me: f64) -> f64 {
    return llvm_intrinsic("llvm.trunc.f64", me)
}

# Min/Max with proper NaN handling
routine f64.min(me: f64, other: f64) -> f64 {
    return llvm_intrinsic("llvm.minnum.f64", me, other)
}

routine f64.max(me: f64, other: f64) -> f64 {
    return llvm_intrinsic("llvm.maxnum.f64", me, other)
}

# Fused multiply-add for better precision
routine f64.fma(me: f64, mul: f64, add: f64) -> f64 {
    return llvm_intrinsic("llvm.fma.f64", me, mul, add)
}

# IEEE 754 bit manipulation
routine f64.as_bits(me: f64) -> s64 {
    return llvm_intrinsic("bitcast", me)  # Reinterpret as s64
}

routine f64(from_bits: BitArray<64>) -> f64 {
    return llvm_intrinsic("bitcast", from_bits)  # Reinterpret BitArray<64> as f64
}

# Extract IEEE 754 components
routine f64.extract_sign(me: f64) -> bool {
    let bits = me.as_bits()
    return (bits >> 63) != 0
}

routine f64.extract_exponent(me: f64) -> s64 {
    let bits = me.as_bits()
    return (bits >> 52) & 0x7FF
}

routine f64.extract_mantissa(me: f64) -> s64 {
    let bits = me.as_bits()
    return bits & 0x000FFFFFFFFFFFFF
}

# Type conversions (using constructor syntax)
routine s64(from_f64: f64) -> s64 {
    return llvm_intrinsic("fptosi", from_f64)   # Float to signed int
}

routine u64(from_f64: f64) -> u64 {
    return llvm_intrinsic("fptoui", from_f64)   # Float to unsigned int
}

routine f32(from_f64: f64) -> f32 {
    return llvm_intrinsic("fptrunc", from_f64)  # Truncate to single precision
}

routine bool(from_f64: f64) -> bool {
    return from_f64 != 0.0
}

# Memory operations (use in danger blocks)
routine f64.load_from_memory(ptr: Snatched<f64>) -> f64 {
    danger! {
        return llvm_intrinsic("load", ptr)
    }
}

routine f64.store_to_memory(me: f64, ptr: Snatched<f64>) {
    danger! {
        return llvm_intrinsic("store", me, ptr)
    }
}

# Parsing and formatting using constructor syntax
routine f64(from_text: Text) -> f64 {
    # Parse Text to f64 using LLVM constant folding when possible
    return 0.0  # Placeholder
}

routine Text(from_f64: f64, precision: s64) -> Text {
    # Convert f64 to Text representation with specified precision
    return ""  # Placeholder
}

# SIMD operations for vectorized f64 processing
routine f64_vec_add(a: slice<f64>, b: slice<f64>) -> slice<f64> {
    let result = new_slice<f64>(a.length())

    # This loop will be auto-vectorized by LLVM using SSE2/AVX
    for i in 0..a.length() {
        result[i] = a[i] + b[i]
    }

    return result
}

routine f64_vec_dot_product(a: slice<f64>, b: slice<f64>) -> f64 {
    let sum: f64 = 0.0
    let length = min(a.length(), b.length())

    # LLVM will vectorize this with horizontal add reductions
    for i in 0..length {
        sum += a[i] * b[i]
    }

    return sum
}

# High-performance mathematical operations
routine fast_inverse_sqrt(value: f64) -> f64 {
    # Fast inverse square root using bit manipulation
    let bits = value.as_bits()
    let magic: s64 = 0x5FE6EC85E7DE30DA  # Magic constant for f64
    let guess = f64.from_bits(magic - (bits >> 1))

    # Newton-Raphson refinement
    let half_value = value * 0.5
    return guess * (1.5 - half_value * guess * guess)
}

routine lerp(a: f64, b: f64, t: f64) -> f64 {
    # Linear interpolation with fused multiply-add
    return a.fma(1.0 - t, b * t)
}

# Numerical computation helpers
routine approx_equal(a: f64, b: f64, epsilon: f64) -> bool {
    return (a - b).abs() <= epsilon
}

routine next_power_of_two(value: f64) -> f64 {
    when value {
        <= 1.0 => 1.0,
        _ => return 2.0.pow(value.ln() / F64_LN_2).ceil()
    }
}

/*
LLVM IR Generation Examples:

RazorForge Code:
    let a: f64 = 3.14159;
    let b: f64 = 2.71828;
    let result: f64 = a * b + 1.0;

Generated LLVM IR:
    %a = alloca double
    %b = alloca double
    %result = alloca double
    store double 3.14159, double* %a
    store double 2.71828, double* %b
    %1 = load double, double* %a
    %2 = load double, double* %b
    %3 = fmul double %1, %2
    %4 = fadd double %3, 1.0
    store double %4, double* %result

Optimized LLVM IR (with fused multiply-add):
    %result = alloca double
    %1 = call double @llvm.fma.f64(double 3.14159, double 2.71828, double 1.0)
    store double %1, double* %result

LLVM Intrinsics Used:
- Arithmetic: fadd, fsub, fmul, fdiv, frem
- Comparison: fcmp (oeq, one, olt, ole, ogt, oge, uno)
- Math: fabs, sqrt, sin, cos, pow, exp, log, etc.
- Rounding: floor, ceil, round, trunc
- Memory: load, store, alloca
- Conversion: fptosi, fptoui, fptrunc, fpext, bitcast
- SIMD: vector operations for packed doubles

IEEE 754 Double Precision Format:
- Sign bit: 1 bit (bit 63)
- Exponent: 11 bits (bits 62-52, biased by 1023)
- Mantissa: 52 bits (bits 51-0, with implicit leading 1)
- Total: 64 bits

Target Architecture Mapping:
- x86_64: Uses SSE2 XMM registers, AVX YMM/ZMM for SIMD
- ARM64: Uses NEON FPU registers, SVE for SIMD
- RISC-V: Uses F/D extension registers
- WebAssembly: Native f64 type with IEEE 754 compliance
*/
